{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dab5f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from typing import TypedDict, Annotated\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from dotenv import load_dotenv \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f0afa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tavily import TavilyClient\n",
    "tavily_client = TavilyClient(api_key=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b955867d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", google_api_key=\"AIzaSyA9sB-9wkCrFEPz0zZytcsrvb9pKtBztlE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0abf2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ashita Aswal\n",
      "Delhi | ashitaaswal10@gmail.com | +91-9428599235 | linkedin | github\n",
      "Summary\n",
      "Passionate about leveraging Generative AI to build innovative applications that enhance user experiences and\n",
      "solve real world problems.\n",
      "Education\n",
      "Uttaranchal University\n",
      "B.Tech in Computer Science and Engineering with a specialization in Machine\n",
      "Learning and Artificial Intelligence.\n",
      "2019 – 2023\n",
      "9.6\n",
      "Experience\n",
      "Associate Software Engineer – [Yamaha Motor Solutions India] FEB 2023 – Present\n",
      "Gen AI Internal Solution\n",
      "• Description: Developed an internal Generative AI-powered application to streamline workflows and enhance\n",
      "efficiency within the organization.\n",
      "• Responsibility: Led end-to-end development, ensuring security , scalability , and seamless AI integration while\n",
      "closely collaborating with the Yamaha Japan team.\n",
      "• Tech Stack: AWS (ECS, S3, VPC, Amazon Bedrock, Cognito, OpenSearch, QuickSight, Lambda), Bing API, Azure\n",
      "Entra ID,Azure OpenAI.\n",
      "One-Stop Solution Application with Multi-modal Capability\n",
      "• Description: Built a Generative AI-driven multi-modal solution for intelligent document analysis, image-based\n",
      "search, and video insights.\n",
      "• Responsibility: Led end-to-end product development, from research to deployment, collaborating closely with\n",
      "the Yamaha Japan team.\n",
      "• Tech Stack: Django Rest Framework, Azure OpenAI, Azure AI Search, Blob Storage.\n",
      "AI Email Agent (POC)\n",
      "• Description: Created an AI-powered agent to generate and send context-aware emails from a single instruction.\n",
      "• Responsibility: Led development using AI-driven automation to streamline email composition and delivery .\n",
      "• Tech Stack: Streamlit, Azure OpenAI, LangChain.\n",
      "Website RAG Chatbot\n",
      "• Description: Built a chatbot with Retrieval-Augmented Generation (RAG) for intelligent, context-aware website\n",
      "interactions.\n",
      "• Responsibility: Developed a scalable chatbot solution for a website.\n",
      "• Tech Stack: AWS (App Runner, OpenSearch, Kendra, Amazon Bedrock, Cognito,Django Rest Framework).\n",
      "Courses and Certificates\n",
      "Python: PCAP-31-03: Certified Associate in Python Programming.\n",
      "Summer School: Attended the CIVIT 8th Summer School on AI at IIIT Hyderabad.\n",
      "Hackathon 2.0: Served as an evaluator for a Yamaha-organized hackathon at IIT Mandi.\n",
      "Django Rest Framework: API by Meta\n",
      "Technologies\n",
      "Languages: Python, SQL, C++, JS\n",
      "Technologies: Django Rest Framework, Flask, Streamlit, Generative AI, langchain, langgraph, AWS, Microsoft\n",
      "Azure, DevOps\n"
     ]
    }
   ],
   "source": [
    "#upload the resume file\n",
    "#extract skills from file\n",
    "#skill match with the skills of job Analysis\n",
    "# return a list of skills missing in your resume. \n",
    "def test():\n",
    "    resume_path = \"Ashita_resume.pdf\"\n",
    "    loader = PyPDFLoader(resume_path)\n",
    "    docs = loader.load()\n",
    "    lst = []\n",
    "    for i, doc in enumerate(docs):\n",
    "       \n",
    "        lst.append(str(doc.page_content))\n",
    "    combined = \" \".join(lst)\n",
    "    print(combined)\n",
    "test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67e433ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResumeAnalyzer(TypedDict):\n",
    "    resume_skills : list[str]\n",
    "    resume_skills_summary : str\n",
    "    feedback : str\n",
    "    highly_required_skills : list[str]\n",
    "    good_to_have_skills : list[str]\n",
    "    already_have : list[str]\n",
    "    need_to_have_skills: list[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dafef290",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResumeSkills(BaseModel):\n",
    "    resume_skills : list[str] = Field(description=\"List of all the skills present in the resume\")\n",
    "    summary : str = Field(description=\"Summary of the whole resume in 100 words\")\n",
    "\n",
    "\n",
    "class checkResumeSkills(BaseModel):\n",
    "    already_have : list[str] = Field(description=\"skills present in High Priority in the job description and on resume\")\n",
    "    need_to_have_skills : str = Field(description=\"skills only present in job descriptions high priority\")\n",
    "\n",
    "class ResumeSkillsCompare(BaseModel):\n",
    "    highly_required_skills : list[str] = Field(description=\"List of all the skills present High Priority in the resume\")\n",
    "    good_to_have_skills : str = Field(description=\"Summary of the whole resume in 100 words\")\n",
    "\n",
    "\n",
    "\n",
    "class PriorityResponsse(BaseModel):\n",
    "    high_priority : list[str] = Field(description=\"This contains high_priority skills\")\n",
    "    medium_priority : list[str] = Field(description=\"This contains medium_priority skills\")\n",
    "    low_priority : list[str] = Field(description=\"This contains low_priority\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e70ee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_skills_from_resume(state: ResumeAnalyzer) -> ResumeAnalyzer:\n",
    "    resume_path = \"Ashita_resume.pdf\"\n",
    "    loader = PyPDFLoader(resume_path)\n",
    "    docs = loader.load()\n",
    "    doc_lst =[]\n",
    "    for i, doc in enumerate(docs):\n",
    "        doc_lst.append(doc.page_content)\n",
    "\n",
    "    complete_resume = \" \".join(doc_lst)\n",
    "    structured_response = model.with_structured_output(ResumeSkills)\n",
    "\n",
    "    prompt = f\"You have provided the Resume text extract all the skills you can find in it and also generate a summary of this Resume : {complete_resume}\"\n",
    "    response = structured_response.invoke(prompt)\n",
    "\n",
    "    return {'resume_skills':response.resume_skills, 'resume_skills_summary': response.summary}\n",
    "\n",
    "def comapare_jd_with_skills(state: ResumeAnalyzer) -> ResumeAnalyzer:\n",
    "    jd_response = PriorityResponsse(high_priority=['Python', 'Machine Learning (Supervised, Unsupervised, Deep Learning)', 'Statistical Analysis', 'Predictive Modeling', 'SQL', 'Analytical and Problem-Solving Skills', 'Communication and Presentation Skills'], medium_priority=['Data Visualization (e.g., Power BI, Tableau)', 'Natural Language Processing (NLP)', 'Data Mining', 'Data Management (ETL, Data Warehousing, Data Governance)', 'Data Modeling', 'Model Deployment (MLOps)', 'Cloud Platforms (e.g., Azure, AWS)', 'R'], low_priority=['Big Data Technologies (e.g., Hadoop, Spark, Kafka)', 'Database Programming', 'Feature Engineering', 'Microsoft Excel (Advanced)'])\n",
    "    jd_high_priority_skills = jd_response.high_priority\n",
    "\n",
    "    structured_response = model.with_structured_output(checkResumeSkills)\n",
    "\n",
    "    prompt = f\"You have provided the list of High proiority skills  {jd_high_priority_skills} and resume skills: {state['resume_skills']} you need to comapre these skills and provide skills already have and required\"\n",
    "    response = structured_response.invoke(prompt)\n",
    "\n",
    "    return {'already_have': response.already_have, 'need_to_have_skills':response.need_to_have_skills}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc4d229e",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(ResumeAnalyzer)\n",
    "\n",
    "graph.add_node(\"extract_skills_from_resume\",extract_skills_from_resume)\n",
    "graph.add_node(\"comapare_jd_with_skills\",comapare_jd_with_skills)\n",
    "\n",
    "graph.add_edge(START,\"extract_skills_from_resume\")\n",
    "graph.add_edge(\"extract_skills_from_resume\",\"comapare_jd_with_skills\")\n",
    "graph.add_edge(\"comapare_jd_with_skills\",END)\n",
    "\n",
    "workflow = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fe1556ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'resume_skills': ['Generative AI',\n",
       "  'Machine Learning',\n",
       "  'Artificial Intelligence',\n",
       "  'Python',\n",
       "  'SQL',\n",
       "  'C++',\n",
       "  'JS',\n",
       "  'Django Rest Framework',\n",
       "  'Flask',\n",
       "  'Streamlit',\n",
       "  'LangChain',\n",
       "  'Langgraph',\n",
       "  'AWS',\n",
       "  'Microsoft Azure',\n",
       "  'DevOps',\n",
       "  'ECS',\n",
       "  'S3',\n",
       "  'VPC',\n",
       "  'Amazon Bedrock',\n",
       "  'Cognito',\n",
       "  'OpenSearch',\n",
       "  'QuickSight',\n",
       "  'Lambda',\n",
       "  'Bing API',\n",
       "  'Azure Entra ID',\n",
       "  'Azure OpenAI',\n",
       "  'Azure AI Search',\n",
       "  'Blob Storage',\n",
       "  'Retrieval-Augmented Generation (RAG)',\n",
       "  'App Runner',\n",
       "  'Kendra'],\n",
       " 'resume_skills_summary': 'Ashita Aswal is an Associate Software Engineer specializing in Generative AI, holding a B.Tech in Computer Science and Engineering with a focus on Machine Learning and Artificial Intelligence. At Yamaha Motor Solutions India, Ashita spearheaded the development of multiple Generative AI applications, including an internal solution for workflow optimization, a multi-modal analysis platform, an AI email agent, and a RAG chatbot. Her responsibilities encompassed end-to-end product development, ensuring security, scalability, and seamless AI integration, often collaborating with the Yamaha Japan team. Ashita is proficient in Python, AWS, Azure, Django Rest Framework, and LangChain, and holds a Python programming certification.',\n",
       " 'already_have': ['Python',\n",
       "  'Machine Learning (Supervised, Unsupervised, Deep Learning)',\n",
       "  'SQL'],\n",
       " 'need_to_have_skills': 'Statistical Analysis, Predictive Modeling, Analytical and Problem-Solving Skills, Communication and Presentation Skills'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_state = {\n",
    "}\n",
    "workflow.invoke(init_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccb32af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7a6e77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.9.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
